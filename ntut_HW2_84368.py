# -*- coding: utf-8 -*-
"""HW2_ver1_已知用火_TRY.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_9tRc1p4haV3hcG8mLeY6m216GLjF2av
"""

#Colab裡kaggle是已安裝的預設模組
# !pip install kaggle

#上傳kaggle.json
# from google.colab import files

# files.upload()

#建立kaggle資料夾
!mkdir ~/.kaggle

#將kaggle.json複製到創建的文件夾中
!cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

# ! kaggle datasets list

#kaggle API
!kaggle datasets download -d ntub110002016/machine-learninghw2

#建立data資料夾
! mkdir data

#解壓縮machine-learningntut-2021-autumn-classification.zip到data資料夾
! unzip machine-learninghw2.zip -d data

#import
import tensorflow.keras.backend as K
import tensorflow.keras as keras
import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import numpy as np
import datetime
import glob
import h5py
import sys
import cv2
import os

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout,LeakyReLU,BatchNormalization
from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint
from tensorflow.keras import datasets,layers,models,callbacks,metrics
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.python.keras.utils.np_utils import to_categorical
from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.models import load_model,Model
from sklearn.model_selection import train_test_split
from tensorflow.keras.optimizers import SGD, Adam
from tensorflow.keras import utils
from random import shuffle

#抓資料夾名稱
classNames=[]
cntClass=0
trainPath='/content/data/theSimpsons-train/train/'

#確認目前工作目錄
workIn=os.getcwd()
#改變目前工作目錄
os.chdir (trainPath)

for d in os.listdir('.'):
    if os.path.isdir(trainPath):
        classNames.append(d)
        cntClass+=1

#變回原本工作目錄
os.chdir (workIn)

print(classNames)
print(cntClass)

#建立變數
labels = []
images = []
name = []
imgW=8
imgH=8

def readPicLabels(path,i):
    for f in os.listdir(path):
        absPath=os.path.abspath(os.path.join(path,f))
        if os.path.isdir(absPath):
            i+=1
            temp=os.path.split(absPath)[-1]
            readPicLabels(absPath, i)
            amount = int(len(os.listdir(path)))
            sys.stdout.write('\r'+'>'*(i)+' '*(amount-i) +'[%s%%]' % (i*100/amount)+temp)
        if f.endswith('.jpg'):
            tmpImg=cv2.imread(absPath)
            tmpImg=cv2.cvtColor(tmpImg,cv2.COLOR_BGR2RGB)
            image = cv2.resize(tmpImg, (imgW, imgH))
            images.append(image)
            labels.append(i-1)
    return images,labels

def readPic(path):
    img,labels=readPicLabels(path,i=0)
    img=np.array(img,dtype=np.float32)/255
    labels=utils.to_categorical(labels,num_classes=50)
    return img,labels

imgs,lbls=readPic(trainPath)

Xtrain,Xtest,Ytrain,Ytest=train_test_split(imgs,lbls,test_size=0.15)

print("Train",Xtrain.shape,Ytrain.shape)
print("Test",Xtest.shape,Ytest.shape)

inputs=(imgH,imgW,3)

model = Sequential()

model.add(Conv2D(128, (3,3) , padding='same',activation='relu', input_shape=inputs))
model.add(BatchNormalization(momentum=0.8))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(256, (3,3) , padding='same',activation='relu'))
model.add(BatchNormalization(momentum=0.8))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(512, (3,3) , padding='same',activation='relu'))
model.add(BatchNormalization(momentum=0.8))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())

model.add(Dense(256,activation='relu'))
model.add(BatchNormalization(momentum=0.8))
model.add(Dropout(0.3))
model.add(Dense(128,activation='relu'))
model.add(BatchNormalization(momentum=0.8))

model.add(Dense(cntClass,activation='softmax'))
model.summary()

model.compile(loss='categorical_crossentropy',optimizer= 'adam', metrics=['accuracy'])

batchSize = 64
epochs = 50
stepsPerEpoch=1000
# run過5+28+50


#REF:https://medium.com/alex-attia-blog/the-simpsons-character-recognition-using-keras-d8e1796eae36
datagen = ImageDataGenerator(
  rotation_range=0.1, # 隨機旋轉範圍內的圖像
  width_shift_range=0.1, # 隨機水平移動圖像
  height_shift_range=0.1, # 隨機垂直移動圖像
  horizontal_flip=True) # 隨機翻轉圖片

datagen.fit(Xtrain)

history=model.fit_generator(datagen.flow(Xtrain, Ytrain, batch_size=batchSize),
                 epochs=epochs,steps_per_epoch=stepsPerEpoch,
                 validation_data=(Xtest,Ytest),
                 shuffle=True,
                 callbacks=[ModelCheckpoint('model.h5',save_best_only=True)])

def plotTrainHistory(history,trainMetrics,valMetrics):
    plt.plot(history.history.get(trainMetrics),'-o')
    plt.plot(history.history.get(valMetrics),'-o')
    plt.ylabel(trainMetrics)
    plt.xlabel('Epochs')
    plt.legend(['train','validation'])

#csv testVer20
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plotTrainHistory(history,'loss','val_loss')

plt.subplot(1,2,2)
plotTrainHistory(history,'accuracy','val_accuracy')

plt.show()

# 預測資料
testPath='/content/data/theSimpsons-test/test/'

def readImages(path):
    images = []
    for i in range(10791):
        image = cv2.resize(cv2.imread(path+str(i+1)+'.jpg'), (imgW, imgH))
        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
        images.append(image)
    images = np.array(images, dtype=np.float32)/255
    return images

readTestImage=readImages(testPath)
print(readTestImage.shape)

model=load_model('model.h5')

pred=model.predict(readTestImage)

pred=np.argmax(pred,axis=1)

# save predict result 
with open('testVer20.csv','w') as f:
    f.write('id,character\n')
    for i in range(10791):
        f.write(str(i+1)+","+str(classNames[pred[i]])+"\n")